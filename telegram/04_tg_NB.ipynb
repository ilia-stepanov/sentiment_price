{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TaDFTaiKTl6l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93490, 300)\n",
      "(93490, 302)\n"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv('/is/prices/tg_join_lab.csv', sep='|')\n",
    "\n",
    "print(f.shape)\n",
    "b = pd.read_csv('/is/prices/tg_bh.csv', sep='|')\n",
    "f = f.merge(b, how='inner', on='ticker')\n",
    "f['obs'] = 1\n",
    "f = f.sort_values('date', ascending=False)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neut:  (11208,)\n",
      "neg:  (11627,)\n",
      "pos:  (12971,)\n"
     ]
    }
   ],
   "source": [
    "j_neut = 0.2\n",
    "j_pos = 2.0\n",
    "j_neg = 2.0\n",
    "i = 1\n",
    "label_neut = f'label_{i}_{j_neut}'\n",
    "label_pos = f'label_{i}_{j_pos}'\n",
    "label_neg = f'label_{i}_{j_neg}'\n",
    "print('neut: ', f[label_neut][f[label_neut]==0].shape)\n",
    "print('neg: ', f[label_neg][f[label_neg]==-1].shape)\n",
    "print('pos: ', f[label_pos][f[label_pos]==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17856"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9*2*4*4*62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Финальный репорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vtbr\n",
      "gmkn\n",
      "zill\n",
      "alrs\n",
      "uwgn\n",
      "tcsg\n",
      "belu\n",
      "lnta\n",
      "hydr\n",
      "sber\n",
      "irao\n",
      "afks\n",
      "gche\n",
      "amez\n",
      "sngs\n",
      "nmtp\n",
      "moex\n",
      "smlt\n",
      "yndx\n",
      "krot\n",
      "five\n",
      "chgz\n",
      "gazp\n",
      "mvid\n",
      "plzl\n",
      "pikk\n",
      "nknc\n",
      "upro\n",
      "paza\n",
      "rosn\n",
      "zvez\n",
      "ucss\n",
      "magn\n",
      "mtlr\n",
      "iskj\n",
      "rtkm0\n",
      "qiwi8\n",
      "tatn6\n",
      "lkoh4\n",
      "rasp2\n",
      "aflt0\n",
      "enru8\n",
      "bane6\n",
      "rbcm4\n",
      "phor2\n",
      "nlmk0\n",
      "rual8\n",
      "mgnt6\n",
      "hals4\n",
      "aptk2\n",
      "lsng0\n",
      "kmaz8\n",
      "mtss6\n",
      "nvtk4\n",
      "chmf2\n",
      "rsti0\n",
      "dsky8\n",
      "mail6\n",
      "tanl4\n",
      "lsrg2\n",
      "rlmn0\n",
      "trmk8\n",
      "17856\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30909</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.984228</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>0.219362</td>\n",
       "      <td>0.982910</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30909</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.303562</td>\n",
       "      <td>0.469253</td>\n",
       "      <td>0.982850</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30909</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.983928</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.369043</td>\n",
       "      <td>0.425925</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30909</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.984116</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.264288</td>\n",
       "      <td>0.840128</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30909</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.727365</td>\n",
       "      <td>0.921994</td>\n",
       "      <td>0.982832</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17851</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4914</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.769988</td>\n",
       "      <td>0.729318</td>\n",
       "      <td>-0.337080</td>\n",
       "      <td>-1.561980</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.512917e-19</td>\n",
       "      <td>0.709185</td>\n",
       "      <td>0.102991</td>\n",
       "      <td>0.645399</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17852</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4914</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.232391</td>\n",
       "      <td>0.729456</td>\n",
       "      <td>-0.222615</td>\n",
       "      <td>-0.016312</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.179073e-19</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.985939</td>\n",
       "      <td>0.632298</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17853</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4914</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.372358</td>\n",
       "      <td>0.726561</td>\n",
       "      <td>-0.769265</td>\n",
       "      <td>0.604388</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.733385e-19</td>\n",
       "      <td>0.399574</td>\n",
       "      <td>0.508043</td>\n",
       "      <td>0.641953</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17854</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4914</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>16.051362</td>\n",
       "      <td>0.726135</td>\n",
       "      <td>-1.669117</td>\n",
       "      <td>-0.741723</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.285814e-19</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>0.408043</td>\n",
       "      <td>0.647261</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17855</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4914</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.070834</td>\n",
       "      <td>0.728491</td>\n",
       "      <td>0.174911</td>\n",
       "      <td>0.315136</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>3.942047e-19</td>\n",
       "      <td>0.855912</td>\n",
       "      <td>0.720971</td>\n",
       "      <td>0.632569</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17856 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   vtbr     1       5     0.2    2.0    2.0       30909       6264   \n",
       "0         1   vtbr     1      10     0.2    2.0    2.0       30909       6264   \n",
       "0         2   vtbr     1      15     0.2    2.0    2.0       30909       6264   \n",
       "0         3   vtbr     1      21     0.2    2.0    2.0       30909       6264   \n",
       "0         4   vtbr     1      28     0.2    2.0    2.0       30909       6264   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0     17851   trmk     1      28     0.5    6.0    6.0        4914        180   \n",
       "0     17852   trmk     1      36     0.5    6.0    6.0        4914        180   \n",
       "0     17853   trmk     1      45     0.5    6.0    6.0        4914        180   \n",
       "0     17854   trmk     1      55     0.5    6.0    6.0        4914        180   \n",
       "0     17855   trmk     1      66     0.5    6.0    6.0        4914        180   \n",
       "\n",
       "     obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   6243  ...   0.000535          0.984228              0.000123   \n",
       "0   6243  ...   0.000574          0.984111              0.000062   \n",
       "0   6243  ...   0.000582          0.983928              0.000054   \n",
       "0   6243  ...   0.000581          0.984116              0.000068   \n",
       "0   6243  ...   0.000619          0.984032             -0.000021   \n",
       "..   ...  ...        ...               ...                   ...   \n",
       "0    179  ...  15.769988          0.729318             -0.337080   \n",
       "0    179  ...  15.232391          0.729456             -0.222615   \n",
       "0    179  ...  15.372358          0.726561             -0.769265   \n",
       "0    179  ...  16.051362          0.726135             -1.669117   \n",
       "0    179  ...  15.070834          0.728491              0.174911   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0               0.000078  0.003992   0.000000e+00           0.044127   \n",
       "0               0.000046  0.001949   0.000000e+00           0.303562   \n",
       "0               0.000050  0.001537   0.000000e+00           0.369043   \n",
       "0               0.000013  0.001734   0.000000e+00           0.264288   \n",
       "0               0.000006  0.000858   0.000000e+00           0.727365   \n",
       "..                   ...       ...            ...                ...   \n",
       "0              -1.561980  0.000020   1.512917e-19           0.709185   \n",
       "0              -0.016312  0.000047   3.179073e-19           0.811583   \n",
       "0               0.604388  0.000035   1.733385e-19           0.399574   \n",
       "0              -0.741723  0.000015   1.285814e-19           0.064713   \n",
       "0               0.315136  0.000059   3.942047e-19           0.855912   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.219362  0.982910  852.0  \n",
       "0            0.469253  0.982850  852.0  \n",
       "0            0.425925  0.982847  852.0  \n",
       "0            0.840128  0.982857  852.0  \n",
       "0            0.921994  0.982832  852.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.102991  0.645399   85.0  \n",
       "0            0.985939  0.632298   85.0  \n",
       "0            0.508043  0.641953   85.0  \n",
       "0            0.408043  0.647261   85.0  \n",
       "0            0.720971  0.632569   85.0  \n",
       "\n",
       "[17856 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_spell_stop_lem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 10, 15, 21, 28, 36, 45, 55, 66] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "j_neuts = [0.2, 0.5]\n",
    "j_poss = [2.0, 3.0, 4.0, 6.0] \n",
    "j_negs = [2.0, 3.0, 4.0, 6.0]\n",
    "days = [1]\n",
    "\n",
    "\n",
    "counter = 0\n",
    "i = 1\n",
    "t = 4\n",
    "\n",
    "# split\n",
    "for ticker in  f.ticker.unique(): #['sber']: #\n",
    "    print(ticker)\n",
    "\n",
    "    for j_neut in j_neuts:\n",
    "        for j_pos in j_poss:\n",
    "            for j_neg in j_negs:\n",
    "                label_neut = f'label_{i}_{j_neut}'\n",
    "                label_pos = f'label_{i}_{j_pos}'\n",
    "                label_neg = f'label_{i}_{j_neg}'\n",
    "                for day in days:\n",
    "                    try:\n",
    "\n",
    "                        ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                        ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                        if t == 0:\n",
    "                            min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                         ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                            ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                            ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                            df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                            ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                           ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                        else:\n",
    "                            min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                         ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                         ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                            ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                            ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                            ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                            df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                            ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                            ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                           ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                        x_train = df[field]\n",
    "                        y_train = df['sentiment'] \n",
    "\n",
    "                    # fit\n",
    "                        for ngram_range_max in ngram_range_maxs:\n",
    "                            for min_df in min_dfs:\n",
    "                                for max_df in max_dfs:\n",
    "\n",
    "                                    tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                             max_df=max_df, \\\n",
    "                                                             ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                    train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                    model = MultinomialNB(alpha=0.1)\n",
    "                                    model.fit(train_features, y_train)\n",
    "                                    y_train_pred = model.predict(train_features)\n",
    "    # В идеале волатильность взять за эти же лаги наверное\n",
    "                                    df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                           [['text_reg_spell_stop_lem', 'obs', 'date',\\\n",
    "                                                             f'change_close_{day}', 'bh', 'close']]).\\\n",
    "        reset_index().drop('index', axis=1)\n",
    "\n",
    "                                    y_pred = model.predict(tf_idf.transform(df_temp.text_reg_spell_stop_lem))\n",
    "\n",
    "                                    df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                    df_temp['neg'] = 0\n",
    "                                    df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                    df_temp['pos'] = 0\n",
    "                                    df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                    df_temp['neut'] = 0\n",
    "                                    df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                    df_temp = df_temp.drop_duplicates().\\\n",
    "                                    groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "    # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "    # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                    df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                    #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                    df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                    df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                    df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                    df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                    df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                    # просто сумма\n",
    "                                    df_temp['sum_sentiment'] = 0\n",
    "                                    df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                    df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "    # дивергенция c добавлением \n",
    "                                    df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                              / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                    #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                    df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                    df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                    res = dict()\n",
    "                                    res['counter'] = [counter]\n",
    "                                    res['ticker'] = [ticker]\n",
    "                                    res['date'] = [day]\n",
    "\n",
    "                                    res['min_df'] = [min_df]\n",
    "\n",
    "                                    res['j_neut'] = [j_neut]\n",
    "                                    res['j_pos'] = [j_pos] \n",
    "                                    res['j_neg'] = [j_neg] \n",
    "\n",
    "                                    res['train_size'] = [y_train.shape[0]]\n",
    "                                    res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                    res['obs'] = \\\n",
    "                                    [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                    res['bh'] = df_temp.bh.max()\n",
    "                                    res['original_return_isna_all'] = \\\n",
    "                                    [(df_temp[f'change_close_{day}']\\\n",
    "                                      [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                    res['model_return_isna_all'] = \\\n",
    "                                    [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                    res['model_return_isna_short'] = \\\n",
    "                                    [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                    res['model_return_isna_long'] = \\\n",
    "                                    [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                    res['model_diver_return_isna_all'] = \\\n",
    "                                    [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                    res['model_diver_return_isna_short'] = \\\n",
    "                                    [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                    res['model_diver_return_isna_long'] = \\\n",
    "                                    [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                    res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                            , average='macro')]\n",
    "\n",
    "\n",
    "                                    res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                            , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                      , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                      , average='macro')]\n",
    "\n",
    "                                    res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                              , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                              , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                    x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                    x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                    x = pd.get_dummies(x, drop_first=True)\n",
    "                                    y = df_temp.close\n",
    "                                    x2 = sm.add_constant(x)\n",
    "                                    lm = sm.OLS(y, x2)\n",
    "                                    res_lm = lm.fit()\n",
    "\n",
    "                                    res['const'] = res_lm.params[0]\n",
    "                                    res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                    res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                    res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                    res['const_p'] = res_lm.pvalues[0]\n",
    "                                    res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                    res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                    res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                    res['r2'] = res_lm.rsquared\n",
    "                                    res['nobs'] = res_lm.nobs\n",
    "                                    counter += 1\n",
    "                                    print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                    res = pd.DataFrame.from_dict(res)\n",
    "                                    \n",
    "                                    out = out.append(pd.DataFrame(res))\n",
    "                                    if counter % 100 == 0: \n",
    "                                        out.to_excel(f'/is/res/nb/nb_model_ind_final.xlsx', index=False)\n",
    "                                    \n",
    "                    except:\n",
    "                        continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/nb_model_ind_final.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vtbr\n",
      "gmkn\n",
      "zill\n",
      "alrs\n",
      "uwgn\n",
      "tcsg\n",
      "belu\n",
      "lnta\n",
      "hydr\n",
      "sber\n",
      "irao\n",
      "afks\n",
      "gche\n",
      "amez\n",
      "sngs\n",
      "nmtp\n",
      "moex9\n",
      "smlt9\n",
      "yndx9\n",
      "krot9\n",
      "five9\n",
      "chgz9\n",
      "gazp9\n",
      "mvid9\n",
      "plzl9\n",
      "pikk9\n",
      "nknc9\n",
      "upro9\n",
      "paza9\n",
      "rosn9\n",
      "zvez9\n",
      "ucss9\n",
      "magn9\n",
      "mtlr9\n",
      "iskj9\n",
      "rtkm8\n",
      "qiwi8\n",
      "tatn8\n",
      "lkoh8\n",
      "rasp8\n",
      "aflt8\n",
      "enru8\n",
      "bane8\n",
      "rbcm8\n",
      "phor8\n",
      "nlmk8\n",
      "rual8\n",
      "mgnt8\n",
      "hals8\n",
      "aptk8\n",
      "lsng8\n",
      "kmaz8\n",
      "mtss8\n",
      "nvtk8\n",
      "chmf8\n",
      "rsti8\n",
      "dsky8\n",
      "mail8\n",
      "tanl8\n",
      "lsrg8\n",
      "rlmn8\n",
      "trmk8\n",
      "39678\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16311</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.984377</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.238640</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16311</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.984594</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.062237</td>\n",
       "      <td>0.156996</td>\n",
       "      <td>0.982905</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16311</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.109404</td>\n",
       "      <td>0.233291</td>\n",
       "      <td>0.982884</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16311</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.984361</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.220340</td>\n",
       "      <td>0.224869</td>\n",
       "      <td>0.982869</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>vtbr</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16311</td>\n",
       "      <td>6264</td>\n",
       "      <td>6243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.984068</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.658136</td>\n",
       "      <td>0.419298</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39673</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.304220</td>\n",
       "      <td>0.727361</td>\n",
       "      <td>0.825639</td>\n",
       "      <td>-0.779243</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.282716e-19</td>\n",
       "      <td>0.377293</td>\n",
       "      <td>0.383744</td>\n",
       "      <td>0.645686</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39674</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.226643</td>\n",
       "      <td>0.725617</td>\n",
       "      <td>0.877826</td>\n",
       "      <td>-0.253445</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>2.765442e-19</td>\n",
       "      <td>0.358748</td>\n",
       "      <td>0.773267</td>\n",
       "      <td>0.638704</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39675</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.211965</td>\n",
       "      <td>0.734854</td>\n",
       "      <td>-0.079911</td>\n",
       "      <td>-1.220525</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.886968e-19</td>\n",
       "      <td>0.931378</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>0.641162</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39676</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.705568</td>\n",
       "      <td>0.725614</td>\n",
       "      <td>-1.112307</td>\n",
       "      <td>-0.382099</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.304992e-18</td>\n",
       "      <td>0.227826</td>\n",
       "      <td>0.708660</td>\n",
       "      <td>0.638589</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39677</td>\n",
       "      <td>trmk</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>180</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>15.035750</td>\n",
       "      <td>0.736314</td>\n",
       "      <td>-0.163364</td>\n",
       "      <td>-1.062463</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.014951e-19</td>\n",
       "      <td>0.865274</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>0.637785</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39678 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   vtbr     1       5    0.10    2.0    2.0       16311       6264   \n",
       "0         1   vtbr     1       7    0.10    2.0    2.0       16311       6264   \n",
       "0         2   vtbr     1      10    0.10    2.0    2.0       16311       6264   \n",
       "0         3   vtbr     1      15    0.10    2.0    2.0       16311       6264   \n",
       "0         4   vtbr     1      21    0.10    2.0    2.0       16311       6264   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0     39673   trmk     1      28    0.05    9.0    9.0        1977        180   \n",
       "0     39674   trmk     1      36    0.05    9.0    9.0        1977        180   \n",
       "0     39675   trmk     1      45    0.05    9.0    9.0        1977        180   \n",
       "0     39676   trmk     1      55    0.05    9.0    9.0        1977        180   \n",
       "0     39677   trmk     1      66    0.05    9.0    9.0        1977        180   \n",
       "\n",
       "     obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   6243  ...   0.000525          0.984377              0.000141   \n",
       "0   6243  ...   0.000525          0.984594              0.000111   \n",
       "0   6243  ...   0.000553          0.984134              0.000096   \n",
       "0   6243  ...   0.000553          0.984361              0.000073   \n",
       "0   6243  ...   0.000589          0.984068              0.000026   \n",
       "..   ...  ...        ...               ...                   ...   \n",
       "0    179  ...  15.304220          0.727361              0.825639   \n",
       "0    179  ...  15.226643          0.725617              0.877826   \n",
       "0    179  ...  15.211965          0.734854             -0.079911   \n",
       "0    179  ...  15.705568          0.725614             -1.112307   \n",
       "0    179  ...  15.035750          0.736314             -0.163364   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0               0.000077  0.004998   0.000000e+00           0.016689   \n",
       "0               0.000091  0.004974   0.000000e+00           0.062237   \n",
       "0               0.000075  0.002805   0.000000e+00           0.109404   \n",
       "0               0.000076  0.002915   0.000000e+00           0.220340   \n",
       "0               0.000052  0.001440   0.000000e+00           0.658136   \n",
       "..                   ...       ...            ...                ...   \n",
       "0              -0.779243  0.000034   1.282716e-19           0.377293   \n",
       "0              -0.253445  0.000040   2.765442e-19           0.358748   \n",
       "0              -1.220525  0.000039   1.886968e-19           0.931378   \n",
       "0              -0.382099  0.000038   1.304992e-18           0.227826   \n",
       "0              -1.062463  0.000050   2.014951e-19           0.865274   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.238640  0.982943  852.0  \n",
       "0            0.156996  0.982905  852.0  \n",
       "0            0.233291  0.982884  852.0  \n",
       "0            0.224869  0.982869  852.0  \n",
       "0            0.419298  0.982841  852.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.383744  0.645686   85.0  \n",
       "0            0.773267  0.638704   85.0  \n",
       "0            0.176901  0.641162   85.0  \n",
       "0            0.708660  0.638589   85.0  \n",
       "0            0.262460  0.637785   85.0  \n",
       "\n",
       "[39678 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_spell_stop_lem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 7, 10, 15, 21, 28, 36, 45, 55, 66] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "j_neuts = [0.1, 0.2, 0.5, 0.05]\n",
    "j_poss = [2.0, 3.0, 5.0, 9.0] \n",
    "j_negs = [2.0, 3.0, 5.0, 9.0]\n",
    "days = [1]\n",
    "\n",
    "\n",
    "counter = 0\n",
    "i = 1\n",
    "t = 4\n",
    "\n",
    "# split\n",
    "for ticker in  f.ticker.unique(): #['sber']: #\n",
    "    print(ticker)\n",
    "\n",
    "    for j_neut in j_neuts:\n",
    "        for j_pos in j_poss:\n",
    "            for j_neg in j_negs:\n",
    "                label_neut = f'label_{i}_{j_neut}'\n",
    "                label_pos = f'label_{i}_{j_pos}'\n",
    "                label_neg = f'label_{i}_{j_neg}'\n",
    "                for day in days:\n",
    "                    try:\n",
    "\n",
    "                        ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                        ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                        if t == 0:\n",
    "                            min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                         ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                            ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                            ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                            df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                            ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                           ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                        else:\n",
    "                            min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                         ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                         ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                            ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                            ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                            ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                            df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                            ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                            ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                           ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                        x_train = df[field]\n",
    "                        y_train = df['sentiment'] \n",
    "\n",
    "                    # fit\n",
    "                        for ngram_range_max in ngram_range_maxs:\n",
    "                            for min_df in min_dfs:\n",
    "                                for max_df in max_dfs:\n",
    "\n",
    "                                    tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                             max_df=max_df, \\\n",
    "                                                             ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                    train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                    model = MultinomialNB(alpha=0.1)\n",
    "                                    model.fit(train_features, y_train)\n",
    "                                    y_train_pred = model.predict(train_features)\n",
    "    # В идеале волатильность взять за эти же лаги наверное\n",
    "                                    df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                           [['text_reg_spell_stop_lem', 'obs', 'date',\\\n",
    "                                                             f'change_close_{day}', 'bh', 'close']]).\\\n",
    "        reset_index().drop('index', axis=1)\n",
    "\n",
    "                                    y_pred = model.predict(tf_idf.transform(df_temp.text_reg_spell_stop_lem))\n",
    "\n",
    "                                    df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                    df_temp['neg'] = 0\n",
    "                                    df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                    df_temp['pos'] = 0\n",
    "                                    df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                    df_temp['neut'] = 0\n",
    "                                    df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                    df_temp = df_temp.drop_duplicates().\\\n",
    "                                    groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "    # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "    # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                    df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                    #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                    df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                    df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                    df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                    df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                    df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                    # просто сумма\n",
    "                                    df_temp['sum_sentiment'] = 0\n",
    "                                    df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                    df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "    # дивергенция c добавлением \n",
    "                                    df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                              / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                    #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                    df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                    df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                    res = dict()\n",
    "                                    res['counter'] = [counter]\n",
    "                                    res['ticker'] = [ticker]\n",
    "                                    res['date'] = [day]\n",
    "\n",
    "                                    res['min_df'] = [min_df]\n",
    "\n",
    "                                    res['j_neut'] = [j_neut]\n",
    "                                    res['j_pos'] = [j_pos] \n",
    "                                    res['j_neg'] = [j_neg] \n",
    "\n",
    "                                    res['train_size'] = [y_train.shape[0]]\n",
    "                                    res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                    res['obs'] = \\\n",
    "                                    [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                    res['bh'] = df_temp.bh.max()\n",
    "                                    res['original_return_isna_all'] = \\\n",
    "                                    [(df_temp[f'change_close_{day}']\\\n",
    "                                      [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                    res['model_return_isna_all'] = \\\n",
    "                                    [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                    res['model_return_isna_short'] = \\\n",
    "                                    [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                    res['model_return_isna_long'] = \\\n",
    "                                    [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                    res['model_diver_return_isna_all'] = \\\n",
    "                                    [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                    res['model_diver_return_isna_short'] = \\\n",
    "                                    [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                    res['model_diver_return_isna_long'] = \\\n",
    "                                    [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                 (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                    res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                            , average='macro')]\n",
    "\n",
    "\n",
    "                                    res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                            , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                      , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                      , average='macro')]\n",
    "\n",
    "                                    res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                              , average='micro')]\n",
    "\n",
    "\n",
    "                                    res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                              , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                    x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                    x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                    x = pd.get_dummies(x, drop_first=True)\n",
    "                                    y = df_temp.close\n",
    "                                    x2 = sm.add_constant(x)\n",
    "                                    lm = sm.OLS(y, x2)\n",
    "                                    res_lm = lm.fit()\n",
    "\n",
    "                                    res['const'] = res_lm.params[0]\n",
    "                                    res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                    res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                    res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                    res['const_p'] = res_lm.pvalues[0]\n",
    "                                    res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                    res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                    res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                    res['r2'] = res_lm.rsquared\n",
    "                                    res['nobs'] = res_lm.nobs\n",
    "                                    counter += 1\n",
    "                                    print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                    res = pd.DataFrame.from_dict(res)\n",
    "                                    \n",
    "                                    out = out.append(pd.DataFrame(res))\n",
    "                                    if counter % 1000 == 0: \n",
    "                                        out.to_excel(f'/is/res/nb/nb_model_ind_final2.xlsx', index=False)\n",
    "                                    \n",
    "                    except:\n",
    "                        continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/nb_model_ind_final2.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39678, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
