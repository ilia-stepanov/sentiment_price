{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TaDFTaiKTl6l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15281, 280)\n"
     ]
    }
   ],
   "source": [
    "f = pd.read_csv('/is/prices/mag_join_lab.csv', sep='|')\n",
    "\n",
    "print(f.shape)\n",
    "b = pd.read_csv('/is/prices/mag_bh.csv', sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15281, 282)\n"
     ]
    }
   ],
   "source": [
    "f = f.merge(b, how='inner', on='ticker')\n",
    "f['obs'] = 1\n",
    "f = f.sort_values('date', ascending=False)\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neut:  (2153,)\n",
      "neg:  (1756,)\n",
      "pos:  (1913,)\n"
     ]
    }
   ],
   "source": [
    "j_neut = 0.8\n",
    "j_pos = 7.0\n",
    "j_neg = 6.0\n",
    "i = 10\n",
    "label_neut = f'label_{i}_{j_neut}'\n",
    "label_pos = f'label_{i}_{j_pos}'\n",
    "label_neg = f'label_{i}_{j_neg}'\n",
    "print('neut: ', f[label_neut][f[label_neut]==0].shape)\n",
    "print('neg: ', f[label_neg][f[label_neg]==-1].shape)\n",
    "print('pos: ', f[label_pos][f[label_pos]==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagi = [1]\n",
    "j_neuts = [0.2]\n",
    "j_poss = [2.0]\n",
    "j_negs = [2.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagi = [2]\n",
    "j_neuts = [0.5]\n",
    "j_poss = [3.0]\n",
    "j_negs=[3.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagi = [5]\n",
    "j_neuts = [0.5]\n",
    "j_poss = [5.0]\n",
    "j_negs = [5.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagi = [10]\n",
    "j_neuts = [0.8]\n",
    "j_poss = [7.0]\n",
    "j_negs = [6.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 3 * 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Финальный репорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irao\n",
      "sber\n",
      "lnta\n",
      "gmkn\n",
      "vtbr\n",
      "nmtp\n",
      "mtss\n",
      "gazp\n",
      "tcsg\n",
      "moex\n",
      "magn\n",
      "five\n",
      "nknc\n",
      "aflt\n",
      "rosn\n",
      "nlmk\n",
      "rual\n",
      "kbtk\n",
      "cbom\n",
      "rosb\n",
      "afks\n",
      "mvid\n",
      "akrn\n",
      "aptk\n",
      "mgnt\n",
      "qiwi\n",
      "plzl\n",
      "tgkd\n",
      "rtkm\n",
      "yndx\n",
      "usbn\n",
      "svav\n",
      "nvtk\n",
      "dvec\n",
      "kmaz\n",
      "mail\n",
      "zill\n",
      "lkoh\n",
      "tanl\n",
      "trcn\n",
      "tnse\n",
      "236\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.994947</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>-0.012506</td>\n",
       "      <td>0.313966</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.380224</td>\n",
       "      <td>0.618302</td>\n",
       "      <td>0.992291</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002931</td>\n",
       "      <td>0.994336</td>\n",
       "      <td>0.043742</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>0.894072</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.062147</td>\n",
       "      <td>0.176362</td>\n",
       "      <td>0.992309</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.722614</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.229077</td>\n",
       "      <td>0.391763</td>\n",
       "      <td>0.992264</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>0.994978</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.391269</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.473127</td>\n",
       "      <td>0.777790</td>\n",
       "      <td>0.992266</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.994688</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.594261</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.329785</td>\n",
       "      <td>0.853725</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.491830</td>\n",
       "      <td>1.004775</td>\n",
       "      <td>-21.986664</td>\n",
       "      <td>-15.755683</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>1.735154e-26</td>\n",
       "      <td>0.313387</td>\n",
       "      <td>0.482777</td>\n",
       "      <td>0.861143</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.621293</td>\n",
       "      <td>1.010197</td>\n",
       "      <td>-29.793071</td>\n",
       "      <td>-37.953098</td>\n",
       "      <td>0.973256</td>\n",
       "      <td>9.924475e-28</td>\n",
       "      <td>0.146204</td>\n",
       "      <td>0.094128</td>\n",
       "      <td>0.866584</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.781049</td>\n",
       "      <td>1.016349</td>\n",
       "      <td>-43.524828</td>\n",
       "      <td>-17.980606</td>\n",
       "      <td>0.859760</td>\n",
       "      <td>4.334243e-28</td>\n",
       "      <td>0.035455</td>\n",
       "      <td>0.430838</td>\n",
       "      <td>0.868595</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>10.760123</td>\n",
       "      <td>1.000083</td>\n",
       "      <td>-44.222341</td>\n",
       "      <td>-6.674324</td>\n",
       "      <td>0.886895</td>\n",
       "      <td>1.450781e-28</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.760993</td>\n",
       "      <td>0.870520</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.976016</td>\n",
       "      <td>1.012130</td>\n",
       "      <td>-39.665721</td>\n",
       "      <td>-7.329784</td>\n",
       "      <td>0.898851</td>\n",
       "      <td>1.241434e-27</td>\n",
       "      <td>0.063120</td>\n",
       "      <td>0.733580</td>\n",
       "      <td>0.866900</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   irao     1       5     0.2    4.0    4.0        1107        397   \n",
       "0         1   irao     1      10     0.2    4.0    4.0        1107        397   \n",
       "0         2   irao     1      15     0.2    4.0    4.0        1107        397   \n",
       "0         3   irao     1      25     0.2    4.0    4.0        1107        397   \n",
       "0         4   irao     1      35     0.2    4.0    4.0        1107        397   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0       231   tnse     1      10     0.2    4.0    4.0        1155         78   \n",
       "0       232   tnse     1      15     0.2    4.0    4.0        1155         78   \n",
       "0       233   tnse     1      25     0.2    4.0    4.0        1155         78   \n",
       "0       234   tnse     1      35     0.2    4.0    4.0        1155         78   \n",
       "0       235   tnse     1      50     0.2    4.0    4.0        1155         78   \n",
       "\n",
       "    obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   396  ...   0.022088          0.994947              0.020300   \n",
       "0   396  ...  -0.002931          0.994336              0.043742   \n",
       "0   396  ...   0.007746          0.995122              0.027500   \n",
       "0   396  ...   0.020037          0.994978              0.017419   \n",
       "0   396  ...   0.012793          0.994688              0.024740   \n",
       "..  ...  ...        ...               ...                   ...   \n",
       "0    77  ...  -1.491830          1.004775            -21.986664   \n",
       "0    77  ...  -2.621293          1.010197            -29.793071   \n",
       "0    77  ... -13.781049          1.016349            -43.524828   \n",
       "0    77  ...  10.760123          1.000083            -44.222341   \n",
       "0    77  ...  -9.976016          1.012130            -39.665721   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0              -0.012506  0.313966   0.000000e+00           0.380224   \n",
       "0               0.035603  0.894072   0.000000e+00           0.062147   \n",
       "0               0.022034  0.722614   0.000000e+00           0.229077   \n",
       "0              -0.007812  0.391269   0.000000e+00           0.473127   \n",
       "0               0.005310  0.594261   0.000000e+00           0.329785   \n",
       "..                   ...       ...            ...                ...   \n",
       "0             -15.755683  0.985352   1.735154e-26           0.313387   \n",
       "0             -37.953098  0.973256   9.924475e-28           0.146204   \n",
       "0             -17.980606  0.859760   4.334243e-28           0.035455   \n",
       "0              -6.674324  0.886895   1.450781e-28           0.025435   \n",
       "0              -7.329784  0.898851   1.241434e-27           0.063120   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.618302  0.992291  353.0  \n",
       "0            0.176362  0.992309  353.0  \n",
       "0            0.391763  0.992264  353.0  \n",
       "0            0.777790  0.992266  353.0  \n",
       "0            0.853725  0.992263  353.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.482777  0.861143   65.0  \n",
       "0            0.094128  0.866584   65.0  \n",
       "0            0.430838  0.868595   65.0  \n",
       "0            0.760993  0.870520   65.0  \n",
       "0            0.733580  0.866900   65.0  \n",
       "\n",
       "[236 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_stop_stem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 10, 15, 25, 35, 50] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "lagi = [1]\n",
    "j_neuts = [0.2]\n",
    "j_poss = [4.0]\n",
    "j_negs = [4.0]\n",
    "days = [1]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "t = 4\n",
    "for i in lagi:\n",
    "    # split\n",
    "    for ticker in  f.ticker.unique(): #['sber']: #\n",
    "        print(ticker)\n",
    "\n",
    "        for j_neut in j_neuts:\n",
    "            for j_pos in j_poss:\n",
    "                for j_neg in j_negs:\n",
    "                    label_neut = f'label_{i}_{j_neut}'\n",
    "                    label_pos = f'label_{i}_{j_pos}'\n",
    "                    label_neg = f'label_{i}_{j_neg}'\n",
    "                    for day in days:\n",
    "                        try:\n",
    "\n",
    "                            ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                            ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                            if t == 0:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                            else:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                                ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                                ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                            x_train = df[field]\n",
    "                            y_train = df['sentiment'] \n",
    "\n",
    "                        # fit\n",
    "                            for ngram_range_max in ngram_range_maxs:\n",
    "                                for min_df in min_dfs:\n",
    "                                    for max_df in max_dfs:\n",
    "\n",
    "                                        tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                                 max_df=max_df, \\\n",
    "                                                                 ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                        train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                        model = MultinomialNB(alpha=0.1)\n",
    "                                        model.fit(train_features, y_train)\n",
    "                                        y_train_pred = model.predict(train_features)\n",
    "        # В идеале волатильность взять за эти же лаги наверное\n",
    "                                        df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                               [[field, 'obs', 'date',\\\n",
    "                                                                 f'change_close_{day}', 'bh', 'close']]).\\\n",
    "            reset_index().drop('index', axis=1)\n",
    "\n",
    "                                        y_pred = model.predict(tf_idf.transform(df_temp[field]))\n",
    "\n",
    "                                        df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                        df_temp['neg'] = 0\n",
    "                                        df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                        df_temp['pos'] = 0\n",
    "                                        df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                        df_temp['neut'] = 0\n",
    "                                        df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                        df_temp = df_temp.drop_duplicates().\\\n",
    "                                        groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "        # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "        # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                        df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                        df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                        df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                        df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                        df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                        # просто сумма\n",
    "                                        df_temp['sum_sentiment'] = 0\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "        # дивергенция c добавлением \n",
    "                                        df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                                  / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                        #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                        df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                        df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                        res = dict()\n",
    "                                        res['counter'] = [counter]\n",
    "                                        res['ticker'] = [ticker]\n",
    "                                        res['date'] = [day]\n",
    "\n",
    "                                        res['min_df'] = [min_df]\n",
    "\n",
    "                                        res['j_neut'] = [j_neut]\n",
    "                                        res['j_pos'] = [j_pos] \n",
    "                                        res['j_neg'] = [j_neg] \n",
    "\n",
    "                                        res['train_size'] = [y_train.shape[0]]\n",
    "                                        res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                        res['obs'] = \\\n",
    "                                        [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                        res['bh'] = df_temp.bh.max()\n",
    "                                        res['original_return_isna_all'] = \\\n",
    "                                        [(df_temp[f'change_close_{day}']\\\n",
    "                                          [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_return_isna_all'] = \\\n",
    "                                        [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_short'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_long'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_diver_return_isna_all'] = \\\n",
    "                                        [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_short'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_long'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                        res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='macro')]\n",
    "\n",
    "\n",
    "                                        res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='macro')]\n",
    "\n",
    "                                        res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                        x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                        x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                        x = pd.get_dummies(x, drop_first=True)\n",
    "                                        y = df_temp.close\n",
    "                                        x2 = sm.add_constant(x)\n",
    "                                        lm = sm.OLS(y, x2)\n",
    "                                        res_lm = lm.fit()\n",
    "\n",
    "                                        res['const'] = res_lm.params[0]\n",
    "                                        res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                        res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                        res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                        res['const_p'] = res_lm.pvalues[0]\n",
    "                                        res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                        res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                        res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                        res['r2'] = res_lm.rsquared\n",
    "                                        res['nobs'] = res_lm.nobs\n",
    "                                        counter += 1\n",
    "                                        print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                        res = pd.DataFrame.from_dict(res)\n",
    "\n",
    "                                        out = out.append(pd.DataFrame(res))\n",
    "                                        if counter % 100 == 0: \n",
    "                                            out.to_excel(f'/is/res/nb/mag_nb_model_ind_final14.xlsx', index=False)\n",
    "\n",
    "                        except:\n",
    "                            continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/mag_nb_model_ind_final14.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irao\n",
      "sber\n",
      "lnta\n",
      "gmkn\n",
      "vtbr\n",
      "nmtp\n",
      "mtss\n",
      "gazp\n",
      "tcsg\n",
      "moex\n",
      "magn\n",
      "five\n",
      "nknc\n",
      "aflt\n",
      "rosn\n",
      "nlmk\n",
      "rual\n",
      "kbtk\n",
      "cbom\n",
      "rosb\n",
      "afks\n",
      "mvid\n",
      "akrn\n",
      "aptk\n",
      "mgnt\n",
      "qiwi\n",
      "plzl\n",
      "tgkd\n",
      "rtkm\n",
      "yndx\n",
      "usbn\n",
      "svav\n",
      "nvtk\n",
      "dvec\n",
      "kmaz\n",
      "mail\n",
      "zill\n",
      "lkoh\n",
      "tanl\n",
      "trcn\n",
      "tnse\n",
      "235\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3951</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>0.995395</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.107166</td>\n",
       "      <td>0.100776</td>\n",
       "      <td>0.992304</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3951</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.995284</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>0.889395</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.130059</td>\n",
       "      <td>0.992298</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3951</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003575</td>\n",
       "      <td>0.994988</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.870592</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.072995</td>\n",
       "      <td>0.121610</td>\n",
       "      <td>0.992309</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3951</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.995195</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.042506</td>\n",
       "      <td>0.993658</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.138009</td>\n",
       "      <td>0.094869</td>\n",
       "      <td>0.992302</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3951</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>0.995418</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>0.051978</td>\n",
       "      <td>0.946344</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.116931</td>\n",
       "      <td>0.046646</td>\n",
       "      <td>0.992326</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4059</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>16.574552</td>\n",
       "      <td>0.994710</td>\n",
       "      <td>-46.694706</td>\n",
       "      <td>3.683718</td>\n",
       "      <td>0.823382</td>\n",
       "      <td>6.504384e-29</td>\n",
       "      <td>0.051590</td>\n",
       "      <td>0.867194</td>\n",
       "      <td>0.874968</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4059</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>38.657930</td>\n",
       "      <td>0.989769</td>\n",
       "      <td>-62.374937</td>\n",
       "      <td>-17.280577</td>\n",
       "      <td>0.599894</td>\n",
       "      <td>6.724603e-29</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.416565</td>\n",
       "      <td>0.877552</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4059</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>14.791721</td>\n",
       "      <td>1.007732</td>\n",
       "      <td>-59.528148</td>\n",
       "      <td>-24.810013</td>\n",
       "      <td>0.843828</td>\n",
       "      <td>1.008011e-28</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>0.872235</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4059</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>22.701828</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>-34.993315</td>\n",
       "      <td>-13.381386</td>\n",
       "      <td>0.770505</td>\n",
       "      <td>7.173716e-28</td>\n",
       "      <td>0.187765</td>\n",
       "      <td>0.597589</td>\n",
       "      <td>0.863572</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4059</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>40.959937</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>-44.070135</td>\n",
       "      <td>-29.315080</td>\n",
       "      <td>0.603905</td>\n",
       "      <td>3.675409e-28</td>\n",
       "      <td>0.113188</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   irao     1       5     0.5    5.0    5.0        3951        397   \n",
       "0         1   irao     1      10     0.5    5.0    5.0        3951        397   \n",
       "0         2   irao     1      15     0.5    5.0    5.0        3951        397   \n",
       "0         3   irao     1      25     0.5    5.0    5.0        3951        397   \n",
       "0         4   irao     1      35     0.5    5.0    5.0        3951        397   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0       230   tnse     1      10     0.5    5.0    5.0        4059         78   \n",
       "0       231   tnse     1      15     0.5    5.0    5.0        4059         78   \n",
       "0       232   tnse     1      25     0.5    5.0    5.0        4059         78   \n",
       "0       233   tnse     1      35     0.5    5.0    5.0        4059         78   \n",
       "0       234   tnse     1      50     0.5    5.0    5.0        4059         78   \n",
       "\n",
       "    obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   396  ...  -0.002187          0.995395              0.036158   \n",
       "0   396  ...  -0.003152          0.995284              0.037770   \n",
       "0   396  ...  -0.003575          0.994988              0.040802   \n",
       "0   396  ...   0.000168          0.995195              0.032905   \n",
       "0   396  ...  -0.001384          0.995418              0.033274   \n",
       "..  ...  ...        ...               ...                   ...   \n",
       "0    77  ...  16.574552          0.994710            -46.694706   \n",
       "0    77  ...  38.657930          0.989769            -62.374937   \n",
       "0    77  ...  14.791721          1.007732            -59.528148   \n",
       "0    77  ...  22.701828          0.994609            -34.993315   \n",
       "0    77  ...  40.959937          0.991161            -44.070135   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0               0.041094  0.919905   0.000000e+00           0.107166   \n",
       "0               0.039181  0.889395   0.000000e+00           0.104901   \n",
       "0               0.039799  0.870592   0.000000e+00           0.072995   \n",
       "0               0.042506  0.993658   0.000000e+00           0.138009   \n",
       "0               0.051978  0.946344   0.000000e+00           0.116931   \n",
       "..                   ...       ...            ...                ...   \n",
       "0               3.683718  0.823382   6.504384e-29           0.051590   \n",
       "0             -17.280577  0.599894   6.724603e-29           0.006494   \n",
       "0             -24.810013  0.843828   1.008011e-28           0.018685   \n",
       "0             -13.381386  0.770505   7.173716e-28           0.187765   \n",
       "0             -29.315080  0.603905   3.675409e-28           0.113188   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.100776  0.992304  353.0  \n",
       "0            0.130059  0.992298  353.0  \n",
       "0            0.121610  0.992309  353.0  \n",
       "0            0.094869  0.992302  353.0  \n",
       "0            0.046646  0.992326  353.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.867194  0.874968   65.0  \n",
       "0            0.416565  0.877552   65.0  \n",
       "0            0.282102  0.872235   65.0  \n",
       "0            0.597589  0.863572   65.0  \n",
       "0            0.289548  0.864537   65.0  \n",
       "\n",
       "[235 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_stop_stem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 10, 15, 25, 35, 50] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "lagi = [5]\n",
    "j_neuts = [0.5]\n",
    "j_poss = [5.0]\n",
    "j_negs = [5.0]\n",
    "\n",
    "days = [1]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "t = 4\n",
    "for i in lagi:\n",
    "    # split\n",
    "    for ticker in  f.ticker.unique(): #['sber']: #\n",
    "        print(ticker)\n",
    "\n",
    "        for j_neut in j_neuts:\n",
    "            for j_pos in j_poss:\n",
    "                for j_neg in j_negs:\n",
    "                    label_neut = f'label_{i}_{j_neut}'\n",
    "                    label_pos = f'label_{i}_{j_pos}'\n",
    "                    label_neg = f'label_{i}_{j_neg}'\n",
    "                    for day in days:\n",
    "                        try:\n",
    "\n",
    "                            ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                            ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                            if t == 0:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                            else:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                                ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                                ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                            x_train = df[field]\n",
    "                            y_train = df['sentiment'] \n",
    "\n",
    "                        # fit\n",
    "                            for ngram_range_max in ngram_range_maxs:\n",
    "                                for min_df in min_dfs:\n",
    "                                    for max_df in max_dfs:\n",
    "\n",
    "                                        tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                                 max_df=max_df, \\\n",
    "                                                                 ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                        train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                        model = MultinomialNB(alpha=0.1)\n",
    "                                        model.fit(train_features, y_train)\n",
    "                                        y_train_pred = model.predict(train_features)\n",
    "        # В идеале волатильность взять за эти же лаги наверное\n",
    "                                        df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                               [[field, 'obs', 'date',\\\n",
    "                                                                 f'change_close_{day}', 'bh', 'close']]).\\\n",
    "            reset_index().drop('index', axis=1)\n",
    "\n",
    "                                        y_pred = model.predict(tf_idf.transform(df_temp[field]))\n",
    "\n",
    "                                        df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                        df_temp['neg'] = 0\n",
    "                                        df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                        df_temp['pos'] = 0\n",
    "                                        df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                        df_temp['neut'] = 0\n",
    "                                        df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                        df_temp = df_temp.drop_duplicates().\\\n",
    "                                        groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "        # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "        # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                        df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                        df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                        df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                        df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                        df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                        # просто сумма\n",
    "                                        df_temp['sum_sentiment'] = 0\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "        # дивергенция c добавлением \n",
    "                                        df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                                  / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                        #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                        df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                        df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                        res = dict()\n",
    "                                        res['counter'] = [counter]\n",
    "                                        res['ticker'] = [ticker]\n",
    "                                        res['date'] = [day]\n",
    "\n",
    "                                        res['min_df'] = [min_df]\n",
    "\n",
    "                                        res['j_neut'] = [j_neut]\n",
    "                                        res['j_pos'] = [j_pos] \n",
    "                                        res['j_neg'] = [j_neg] \n",
    "\n",
    "                                        res['train_size'] = [y_train.shape[0]]\n",
    "                                        res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                        res['obs'] = \\\n",
    "                                        [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                        res['bh'] = df_temp.bh.max()\n",
    "                                        res['original_return_isna_all'] = \\\n",
    "                                        [(df_temp[f'change_close_{day}']\\\n",
    "                                          [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_return_isna_all'] = \\\n",
    "                                        [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_short'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_long'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_diver_return_isna_all'] = \\\n",
    "                                        [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_short'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_long'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                        res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='macro')]\n",
    "\n",
    "\n",
    "                                        res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='macro')]\n",
    "\n",
    "                                        res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                        x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                        x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                        x = pd.get_dummies(x, drop_first=True)\n",
    "                                        y = df_temp.close\n",
    "                                        x2 = sm.add_constant(x)\n",
    "                                        lm = sm.OLS(y, x2)\n",
    "                                        res_lm = lm.fit()\n",
    "\n",
    "                                        res['const'] = res_lm.params[0]\n",
    "                                        res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                        res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                        res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                        res['const_p'] = res_lm.pvalues[0]\n",
    "                                        res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                        res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                        res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                        res['r2'] = res_lm.rsquared\n",
    "                                        res['nobs'] = res_lm.nobs\n",
    "                                        counter += 1\n",
    "                                        print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                        res = pd.DataFrame.from_dict(res)\n",
    "\n",
    "                                        out = out.append(pd.DataFrame(res))\n",
    "                                        if counter % 100 == 0: \n",
    "                                            out.to_excel(f'/is/res/nb/mag_nb_model_ind_final5.xlsx', index=False)\n",
    "\n",
    "                        except:\n",
    "                            continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/mag_nb_model_ind_final5.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irao\n",
      "sber\n",
      "lnta\n",
      "gmkn\n",
      "vtbr\n",
      "nmtp\n",
      "mtss\n",
      "gazp\n",
      "tcsg\n",
      "moex\n",
      "magn\n",
      "five\n",
      "nknc\n",
      "aflt\n",
      "rosn\n",
      "nlmk\n",
      "rual\n",
      "kbtk\n",
      "cbom\n",
      "rosb\n",
      "afks\n",
      "mvid\n",
      "akrn\n",
      "aptk\n",
      "mgnt\n",
      "qiwi\n",
      "plzl\n",
      "tgkd\n",
      "rtkm\n",
      "yndx\n",
      "usbn\n",
      "svav\n",
      "nvtk\n",
      "dvec\n",
      "kmaz\n",
      "mail\n",
      "zill\n",
      "lkoh\n",
      "tanl\n",
      "trcn\n",
      "tnse\n",
      "243\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.995037</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>-0.002810</td>\n",
       "      <td>0.454957</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>0.914287</td>\n",
       "      <td>0.992316</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.995297</td>\n",
       "      <td>0.037167</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.684458</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.058652</td>\n",
       "      <td>0.863650</td>\n",
       "      <td>0.992324</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.995494</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.391520</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.342278</td>\n",
       "      <td>0.914357</td>\n",
       "      <td>0.992255</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017133</td>\n",
       "      <td>0.995899</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>-0.026337</td>\n",
       "      <td>0.398162</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.230707</td>\n",
       "      <td>0.320270</td>\n",
       "      <td>0.992347</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.995389</td>\n",
       "      <td>0.028682</td>\n",
       "      <td>-0.011929</td>\n",
       "      <td>0.511870</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.184043</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>0.992317</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4557</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>30.699063</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>-45.932711</td>\n",
       "      <td>-24.457205</td>\n",
       "      <td>0.687607</td>\n",
       "      <td>3.171050e-28</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>0.420336</td>\n",
       "      <td>0.869777</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4557</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>22.376036</td>\n",
       "      <td>1.005592</td>\n",
       "      <td>-46.658071</td>\n",
       "      <td>-28.104598</td>\n",
       "      <td>0.770727</td>\n",
       "      <td>7.579096e-28</td>\n",
       "      <td>0.043368</td>\n",
       "      <td>0.384024</td>\n",
       "      <td>0.868196</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4557</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>36.119558</td>\n",
       "      <td>1.004621</td>\n",
       "      <td>-63.087892</td>\n",
       "      <td>-34.542620</td>\n",
       "      <td>0.626290</td>\n",
       "      <td>5.033891e-29</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.241557</td>\n",
       "      <td>0.875859</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4557</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>23.745466</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>-39.895058</td>\n",
       "      <td>-12.685262</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>3.384539e-28</td>\n",
       "      <td>0.054391</td>\n",
       "      <td>0.658749</td>\n",
       "      <td>0.867953</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4557</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>25.542803</td>\n",
       "      <td>0.997649</td>\n",
       "      <td>-40.191833</td>\n",
       "      <td>-11.679182</td>\n",
       "      <td>0.737345</td>\n",
       "      <td>1.848610e-28</td>\n",
       "      <td>0.050137</td>\n",
       "      <td>0.691599</td>\n",
       "      <td>0.868236</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   irao     1       5     0.5    3.0    3.0        4428        397   \n",
       "0         1   irao     1      10     0.5    3.0    3.0        4428        397   \n",
       "0         2   irao     1      15     0.5    3.0    3.0        4428        397   \n",
       "0         3   irao     1      25     0.5    3.0    3.0        4428        397   \n",
       "0         4   irao     1      35     0.5    3.0    3.0        4428        397   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0       238   tnse     1      10     0.5    3.0    3.0        4557         78   \n",
       "0       239   tnse     1      15     0.5    3.0    3.0        4557         78   \n",
       "0       240   tnse     1      25     0.5    3.0    3.0        4557         78   \n",
       "0       241   tnse     1      35     0.5    3.0    3.0        4557         78   \n",
       "0       242   tnse     1      50     0.5    3.0    3.0        4557         78   \n",
       "\n",
       "    obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   396  ...   0.013352          0.995037              0.033523   \n",
       "0   396  ...   0.007695          0.995297              0.037167   \n",
       "0   396  ...   0.016416          0.995494              0.018855   \n",
       "0   396  ...   0.017133          0.995899              0.025055   \n",
       "0   396  ...   0.013274          0.995389              0.028682   \n",
       "..  ...  ...        ...               ...                   ...   \n",
       "0    77  ...  30.699063          0.998136            -45.932711   \n",
       "0    77  ...  22.376036          1.005592            -46.658071   \n",
       "0    77  ...  36.119558          1.004621            -63.087892   \n",
       "0    77  ...  23.745466          0.998510            -39.895058   \n",
       "0    77  ...  25.542803          0.997649            -40.191833   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0              -0.002810  0.454957   0.000000e+00           0.083804   \n",
       "0               0.004607  0.684458   0.000000e+00           0.058652   \n",
       "0               0.002992  0.391520   0.000000e+00           0.342278   \n",
       "0              -0.026337  0.398162   0.000000e+00           0.230707   \n",
       "0              -0.011929  0.511870   0.000000e+00           0.184043   \n",
       "..                   ...       ...            ...                ...   \n",
       "0             -24.457205  0.687607   3.171050e-28           0.028274   \n",
       "0             -28.104598  0.770727   7.579096e-28           0.043368   \n",
       "0             -34.542620  0.626290   5.033891e-29           0.006661   \n",
       "0             -12.685262  0.755626   3.384539e-28           0.054391   \n",
       "0             -11.679182  0.737345   1.848610e-28           0.050137   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.914287  0.992316  353.0  \n",
       "0            0.863650  0.992324  353.0  \n",
       "0            0.914357  0.992255  353.0  \n",
       "0            0.320270  0.992347  353.0  \n",
       "0            0.660804  0.992317  353.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.420336  0.869777   65.0  \n",
       "0            0.384024  0.868196   65.0  \n",
       "0            0.241557  0.875859   65.0  \n",
       "0            0.658749  0.867953   65.0  \n",
       "0            0.691599  0.868236   65.0  \n",
       "\n",
       "[243 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_stop_stem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 10, 15, 25, 35, 50] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "lagi = [2]\n",
    "j_neuts = [0.5]\n",
    "j_poss = [3.0]\n",
    "j_negs=[3.0]\n",
    "days = [1]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "t = 4\n",
    "for i in lagi:\n",
    "    # split\n",
    "    for ticker in  f.ticker.unique(): #['sber']: #\n",
    "        print(ticker)\n",
    "\n",
    "        for j_neut in j_neuts:\n",
    "            for j_pos in j_poss:\n",
    "                for j_neg in j_negs:\n",
    "                    label_neut = f'label_{i}_{j_neut}'\n",
    "                    label_pos = f'label_{i}_{j_pos}'\n",
    "                    label_neg = f'label_{i}_{j_neg}'\n",
    "                    for day in days:\n",
    "                        try:\n",
    "\n",
    "                            ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                            ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                            if t == 0:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                            else:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                                ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                                ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                            x_train = df[field]\n",
    "                            y_train = df['sentiment'] \n",
    "\n",
    "                        # fit\n",
    "                            for ngram_range_max in ngram_range_maxs:\n",
    "                                for min_df in min_dfs:\n",
    "                                    for max_df in max_dfs:\n",
    "\n",
    "                                        tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                                 max_df=max_df, \\\n",
    "                                                                 ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                        train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                        model = MultinomialNB(alpha=0.1)\n",
    "                                        model.fit(train_features, y_train)\n",
    "                                        y_train_pred = model.predict(train_features)\n",
    "        # В идеале волатильность взять за эти же лаги наверное\n",
    "                                        df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                               [[field, 'obs', 'date',\\\n",
    "                                                                 f'change_close_{day}', 'bh', 'close']]).\\\n",
    "            reset_index().drop('index', axis=1)\n",
    "\n",
    "                                        y_pred = model.predict(tf_idf.transform(df_temp[field]))\n",
    "\n",
    "                                        df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                        df_temp['neg'] = 0\n",
    "                                        df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                        df_temp['pos'] = 0\n",
    "                                        df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                        df_temp['neut'] = 0\n",
    "                                        df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                        df_temp = df_temp.drop_duplicates().\\\n",
    "                                        groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "        # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "        # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                        df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                        df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                        df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                        df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                        df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                        # просто сумма\n",
    "                                        df_temp['sum_sentiment'] = 0\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "        # дивергенция c добавлением \n",
    "                                        df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                                  / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                        #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                        df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                        df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                        res = dict()\n",
    "                                        res['counter'] = [counter]\n",
    "                                        res['ticker'] = [ticker]\n",
    "                                        res['date'] = [day]\n",
    "\n",
    "                                        res['min_df'] = [min_df]\n",
    "\n",
    "                                        res['j_neut'] = [j_neut]\n",
    "                                        res['j_pos'] = [j_pos] \n",
    "                                        res['j_neg'] = [j_neg] \n",
    "\n",
    "                                        res['train_size'] = [y_train.shape[0]]\n",
    "                                        res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                        res['obs'] = \\\n",
    "                                        [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                        res['bh'] = df_temp.bh.max()\n",
    "                                        res['original_return_isna_all'] = \\\n",
    "                                        [(df_temp[f'change_close_{day}']\\\n",
    "                                          [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_return_isna_all'] = \\\n",
    "                                        [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_short'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_long'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_diver_return_isna_all'] = \\\n",
    "                                        [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_short'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_long'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                        res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='macro')]\n",
    "\n",
    "\n",
    "                                        res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='macro')]\n",
    "\n",
    "                                        res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                        x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                        x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                        x = pd.get_dummies(x, drop_first=True)\n",
    "                                        y = df_temp.close\n",
    "                                        x2 = sm.add_constant(x)\n",
    "                                        lm = sm.OLS(y, x2)\n",
    "                                        res_lm = lm.fit()\n",
    "\n",
    "                                        res['const'] = res_lm.params[0]\n",
    "                                        res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                        res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                        res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                        res['const_p'] = res_lm.pvalues[0]\n",
    "                                        res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                        res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                        res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                        res['r2'] = res_lm.rsquared\n",
    "                                        res['nobs'] = res_lm.nobs\n",
    "                                        counter += 1\n",
    "                                        print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                        res = pd.DataFrame.from_dict(res)\n",
    "\n",
    "                                        out = out.append(pd.DataFrame(res))\n",
    "                                        if counter % 100 == 0: \n",
    "                                            out.to_excel(f'/is/res/nb/mag_nb_model_ind_final2.xlsx', index=False)\n",
    "\n",
    "                        except:\n",
    "                            continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/mag_nb_model_ind_final2.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irao\n",
      "sber\n",
      "lnta\n",
      "gmkn\n",
      "vtbr\n",
      "nmtp\n",
      "mtss\n",
      "gazp\n",
      "tcsg\n",
      "moex\n",
      "magn\n",
      "five\n",
      "nknc\n",
      "aflt\n",
      "rosn\n",
      "nlmk\n",
      "rual\n",
      "kbtk\n",
      "cbom\n",
      "rosb\n",
      "afks\n",
      "mvid\n",
      "akrn\n",
      "aptk\n",
      "mgnt\n",
      "qiwi\n",
      "plzl\n",
      "tgkd\n",
      "rtkm\n",
      "yndx\n",
      "usbn\n",
      "svav\n",
      "nvtk\n",
      "dvec\n",
      "kmaz\n",
      "mail\n",
      "zill\n",
      "lkoh\n",
      "tanl\n",
      "trcn\n",
      "tnse\n",
      "239\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>min_df</th>\n",
       "      <th>j_neut</th>\n",
       "      <th>j_pos</th>\n",
       "      <th>j_neg</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>obs</th>\n",
       "      <th>...</th>\n",
       "      <th>const</th>\n",
       "      <th>close_lag_1_coef</th>\n",
       "      <th>sum_sentiment_0_coef</th>\n",
       "      <th>sum_sentiment_1_coef</th>\n",
       "      <th>const_p</th>\n",
       "      <th>close_lag_1_p</th>\n",
       "      <th>sum_sentiment_0_p</th>\n",
       "      <th>sum_sentiment_1_p</th>\n",
       "      <th>r2</th>\n",
       "      <th>nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4647</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.994959</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>0.332967</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.273654</td>\n",
       "      <td>0.802503</td>\n",
       "      <td>0.992278</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4647</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>0.995269</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>-0.026709</td>\n",
       "      <td>0.246910</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.292939</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.992331</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4647</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.995567</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.034554</td>\n",
       "      <td>0.165103</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.188959</td>\n",
       "      <td>0.992314</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4647</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.995321</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>-0.013447</td>\n",
       "      <td>0.311424</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.549341</td>\n",
       "      <td>0.631555</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>irao</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4647</td>\n",
       "      <td>397</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047335</td>\n",
       "      <td>0.996576</td>\n",
       "      <td>-0.021679</td>\n",
       "      <td>-0.053987</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.332167</td>\n",
       "      <td>0.052995</td>\n",
       "      <td>0.992316</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4791</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>23.100664</td>\n",
       "      <td>0.987808</td>\n",
       "      <td>-28.066861</td>\n",
       "      <td>29.452588</td>\n",
       "      <td>0.764141</td>\n",
       "      <td>1.094457e-28</td>\n",
       "      <td>0.122286</td>\n",
       "      <td>0.261891</td>\n",
       "      <td>0.871237</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4791</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>15.211824</td>\n",
       "      <td>0.991373</td>\n",
       "      <td>-26.111049</td>\n",
       "      <td>33.703271</td>\n",
       "      <td>0.839886</td>\n",
       "      <td>6.889696e-29</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.179464</td>\n",
       "      <td>0.872216</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4791</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>22.680179</td>\n",
       "      <td>0.994064</td>\n",
       "      <td>-44.057548</td>\n",
       "      <td>-14.364444</td>\n",
       "      <td>0.764399</td>\n",
       "      <td>1.128744e-28</td>\n",
       "      <td>0.026233</td>\n",
       "      <td>0.500154</td>\n",
       "      <td>0.869851</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4791</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>15.265632</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>-47.911913</td>\n",
       "      <td>-14.159434</td>\n",
       "      <td>0.839356</td>\n",
       "      <td>6.937787e-29</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>0.499672</td>\n",
       "      <td>0.871696</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238</td>\n",
       "      <td>tnse</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4791</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.600335</td>\n",
       "      <td>1.013245</td>\n",
       "      <td>-45.000485</td>\n",
       "      <td>-16.347759</td>\n",
       "      <td>0.902134</td>\n",
       "      <td>3.445522e-28</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.469270</td>\n",
       "      <td>0.869220</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    counter ticker  date  min_df  j_neut  j_pos  j_neg  train_size  test_size  \\\n",
       "0         0   irao     1       5     0.2    2.0    2.0        4647        397   \n",
       "0         1   irao     1      10     0.2    2.0    2.0        4647        397   \n",
       "0         2   irao     1      15     0.2    2.0    2.0        4647        397   \n",
       "0         3   irao     1      25     0.2    2.0    2.0        4647        397   \n",
       "0         4   irao     1      35     0.2    2.0    2.0        4647        397   \n",
       "..      ...    ...   ...     ...     ...    ...    ...         ...        ...   \n",
       "0       234   tnse     1      10     0.2    2.0    2.0        4791         78   \n",
       "0       235   tnse     1      15     0.2    2.0    2.0        4791         78   \n",
       "0       236   tnse     1      25     0.2    2.0    2.0        4791         78   \n",
       "0       237   tnse     1      35     0.2    2.0    2.0        4791         78   \n",
       "0       238   tnse     1      50     0.2    2.0    2.0        4791         78   \n",
       "\n",
       "    obs  ...      const  close_lag_1_coef  sum_sentiment_0_coef  \\\n",
       "0   396  ...   0.018642          0.994959              0.022678   \n",
       "0   396  ...   0.022373          0.995269              0.021382   \n",
       "0   396  ...   0.027999          0.995567              0.010095   \n",
       "0   396  ...   0.021841          0.995321              0.013395   \n",
       "0   396  ...   0.047335          0.996576             -0.021679   \n",
       "..  ...  ...        ...               ...                   ...   \n",
       "0    77  ...  23.100664          0.987808            -28.066861   \n",
       "0    77  ...  15.211824          0.991373            -26.111049   \n",
       "0    77  ...  22.680179          0.994064            -44.057548   \n",
       "0    77  ...  15.265632          0.999254            -47.911913   \n",
       "0    77  ...  -9.600335          1.013245            -45.000485   \n",
       "\n",
       "    sum_sentiment_1_coef   const_p  close_lag_1_p  sum_sentiment_0_p  \\\n",
       "0              -0.006244  0.332967   0.000000e+00           0.273654   \n",
       "0              -0.026709  0.246910   0.000000e+00           0.292939   \n",
       "0              -0.034554  0.165103   0.000000e+00           0.630488   \n",
       "0              -0.013447  0.311424   0.000000e+00           0.549341   \n",
       "0              -0.053987  0.029519   0.000000e+00           0.332167   \n",
       "..                   ...       ...            ...                ...   \n",
       "0              29.452588  0.764141   1.094457e-28           0.122286   \n",
       "0              33.703271  0.839886   6.889696e-29           0.152358   \n",
       "0             -14.364444  0.764399   1.128744e-28           0.026233   \n",
       "0             -14.159434  0.839356   6.937787e-29           0.016183   \n",
       "0             -16.347759  0.902134   3.445522e-28           0.029938   \n",
       "\n",
       "    sum_sentiment_1_p        r2   nobs  \n",
       "0            0.802503  0.992278  353.0  \n",
       "0            0.288758  0.992331  353.0  \n",
       "0            0.188959  0.992314  353.0  \n",
       "0            0.631555  0.992263  353.0  \n",
       "0            0.052995  0.992316  353.0  \n",
       "..                ...       ...    ...  \n",
       "0            0.261891  0.871237   65.0  \n",
       "0            0.179464  0.872216   65.0  \n",
       "0            0.500154  0.869851   65.0  \n",
       "0            0.499672  0.871696   65.0  \n",
       "0            0.469270  0.869220   65.0  \n",
       "\n",
       "[239 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "field = 'text_reg_stop_stem'\n",
    "out = pd.DataFrame()\n",
    "\n",
    "min_dfs = [5, 10, 15, 25, 35, 50] \n",
    "max_dfs = [0.5]\n",
    "ngram_range_maxs = [1]\n",
    "\n",
    "lagi = [1]\n",
    "j_neuts = [0.2]\n",
    "j_poss = [2.0]\n",
    "j_negs = [2.0]\n",
    "\n",
    "days = [1]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "t = 4\n",
    "for i in lagi:\n",
    "    # split\n",
    "    for ticker in  f.ticker.unique(): #['sber']: #\n",
    "        print(ticker)\n",
    "\n",
    "        for j_neut in j_neuts:\n",
    "            for j_pos in j_poss:\n",
    "                for j_neg in j_negs:\n",
    "                    label_neut = f'label_{i}_{j_neut}'\n",
    "                    label_pos = f'label_{i}_{j_pos}'\n",
    "                    label_neg = f'label_{i}_{j_neg}'\n",
    "                    for day in days:\n",
    "                        try:\n",
    "\n",
    "                            ps = f[[label_neut, label_pos, label_neg, field]][(f.ticker!=ticker)] \n",
    "                            ps = ps.loc[:,~ps.columns.duplicated()]\n",
    "                            if t == 0:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neg]==-1)].sample(frac=1, random_state=42)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neg:'sentiment'}), \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "                            else:\n",
    "                                min_df = min(ps[(ps[label_pos]==1)].shape[0], \\\n",
    "                                             ps[(ps[label_neut]==0)].shape[0], \\\n",
    "                                             ps[(ps[label_neg]==-1)].shape[0])\n",
    "\n",
    "                                ps1 = ps[(ps[label_pos]==1)][[label_pos, field]].sample(frac=1, random_state=41)\n",
    "                                ps2 = ps[(ps[label_neut]==0)][[label_neut, field]].sample(frac=1, random_state=42)\n",
    "                                ps3 = ps[(ps[label_neg]==-1)][[label_neg, field]].sample(frac=1, random_state=43)\n",
    "\n",
    "                                df = pd.concat([ps1[:min_df].rename(columns={label_pos:'sentiment'}), \\\n",
    "                                                ps2[:min_df].rename(columns={label_neut:'sentiment'}), \\\n",
    "                                                ps3[:min_df].rename(columns={label_neg:'sentiment'}) \\\n",
    "                                               ]).sample(frac=1, random_state=44)\n",
    "\n",
    "\n",
    "                            x_train = df[field]\n",
    "                            y_train = df['sentiment'] \n",
    "\n",
    "                        # fit\n",
    "                            for ngram_range_max in ngram_range_maxs:\n",
    "                                for min_df in min_dfs:\n",
    "                                    for max_df in max_dfs:\n",
    "\n",
    "                                        tf_idf = TfidfVectorizer(min_df=min_df, \\\n",
    "                                                                 max_df=max_df, \\\n",
    "                                                                 ngram_range=(1, ngram_range_max))\n",
    "\n",
    "                                        train_features = tf_idf.fit_transform(x_train)\n",
    "\n",
    "\n",
    "                                        model = MultinomialNB(alpha=0.1)\n",
    "                                        model.fit(train_features, y_train)\n",
    "                                        y_train_pred = model.predict(train_features)\n",
    "        # В идеале волатильность взять за эти же лаги наверное\n",
    "                                        df_temp = pd.DataFrame(f[(f.ticker==ticker)]\\\n",
    "                                                               [[field, 'obs', 'date',\\\n",
    "                                                                 f'change_close_{day}', 'bh', 'close']]).\\\n",
    "            reset_index().drop('index', axis=1)\n",
    "\n",
    "                                        y_pred = model.predict(tf_idf.transform(df_temp[field]))\n",
    "\n",
    "                                        df_temp['sentiment'] = y_pred\n",
    "\n",
    "                                        df_temp['neg'] = 0\n",
    "                                        df_temp['neg'][df_temp.sentiment==-1] = 1\n",
    "\n",
    "                                        df_temp['pos'] = 0\n",
    "                                        df_temp['pos'][df_temp.sentiment==1] = 1\n",
    "\n",
    "                                        df_temp['neut'] = 0\n",
    "                                        df_temp['neut'][df_temp.sentiment==0] = 1\n",
    "\n",
    "                                        df_temp = df_temp.drop_duplicates().\\\n",
    "                                        groupby(['date', f'change_close_{day}', 'bh', 'close']).sum().reset_index()\n",
    "\n",
    "        # Делаем сум роллинг окно для суммирования сентиментов для периодов больше 1 дня \n",
    "        # Нужно удостовериться в сортировке должно быть по возрастанию даты\n",
    "\n",
    "                                        df_temp[f'close_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        #df_temp[f'close_change_lag_1'] = df_temp.close.shift(periods=1)\n",
    "                                        df_temp = df_temp.sort_values('date', ascending=True)\n",
    "\n",
    "                                        df_temp['neg'] = df_temp['neg'].rolling(day).sum()\n",
    "                                        df_temp['pos'] = df_temp['pos'].rolling(day).sum()\n",
    "                                        df_temp['neut'] = df_temp['neut'].rolling(day).sum()\n",
    "\n",
    "                                        df_temp.dropna(subset=['neg', 'pos', 'neut', 'close_lag_1'], inplace=True)\n",
    "                        # просто сумма\n",
    "                                        df_temp['sum_sentiment'] = 0\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos>df_temp.neg)&(df_temp.pos>=df_temp.neut)] = 1\n",
    "                                        df_temp['sum_sentiment'][(df_temp.pos<df_temp.neg)&(df_temp.neg>=df_temp.neut)] = -1\n",
    "\n",
    "        # дивергенция c добавлением \n",
    "                                        df_temp['diver'] = ((df_temp.pos - df_temp.neg)**2 \\\n",
    "                                                                  / (df_temp.pos + df_temp.neg)**2)**(1/2)\n",
    "\n",
    "                                        #df_temp.reset_index(level=[f'change_close_{day}', 'date', 'bh'], inplace=True)\n",
    "                                        df_temp['clear_return'] = df_temp.sum_sentiment * df_temp[f'change_close_{day}']\n",
    "                                        df_temp['diver_return'] = df_temp.clear_return * df_temp.diver                \n",
    "\n",
    "                                        res = dict()\n",
    "                                        res['counter'] = [counter]\n",
    "                                        res['ticker'] = [ticker]\n",
    "                                        res['date'] = [day]\n",
    "\n",
    "                                        res['min_df'] = [min_df]\n",
    "\n",
    "                                        res['j_neut'] = [j_neut]\n",
    "                                        res['j_pos'] = [j_pos] \n",
    "                                        res['j_neg'] = [j_neg] \n",
    "\n",
    "                                        res['train_size'] = [y_train.shape[0]]\n",
    "                                        res['test_size'] = [y_pred.shape[0]]\n",
    "\n",
    "                                        res['obs'] = \\\n",
    "                                        [(df_temp.obs[df_temp.clear_return.isna()==False]).sum()]\n",
    "                                        res['bh'] = df_temp.bh.max()\n",
    "                                        res['original_return_isna_all'] = \\\n",
    "                                        [(df_temp[f'change_close_{day}']\\\n",
    "                                          [df_temp[f'change_close_{day}'].isna()==False]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_return_isna_all'] = \\\n",
    "                                        [(df_temp.clear_return[df_temp.clear_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_short'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_return_isna_long'] = \\\n",
    "                                        [(df_temp.clear_return[(df_temp.clear_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "                                        res['model_diver_return_isna_all'] = \\\n",
    "                                        [(df_temp.diver_return[df_temp.diver_return.isna()==False]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_short'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=1)]).sum()]\n",
    "\n",
    "                                        res['model_diver_return_isna_long'] = \\\n",
    "                                        [(df_temp.diver_return[(df_temp.diver_return.isna()==False) & \\\n",
    "                                                                     (df_temp.sum_sentiment!=-1)]).sum()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        res['train_accuracy'] = [metrics.accuracy_score(y_train_pred, y_train)]\n",
    "\n",
    "\n",
    "                                        res['train_precision_macro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='macro')]\n",
    "\n",
    "\n",
    "                                        res['train_precision_micro'] = [metrics.precision_score(y_train_pred, y_train\\\n",
    "                                                                                                , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_micro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_recall_macro'] = [metrics.recall_score(y_train_pred, y_train\\\n",
    "                                                                                          , average='macro')]\n",
    "\n",
    "                                        res['train_f1_micro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='micro')]\n",
    "\n",
    "\n",
    "                                        res['train_f1_macro'] = [metrics.f1_score(y_train_pred, y_train\\\n",
    "                                                                                  , average='macro')]\n",
    "\n",
    "\n",
    "\n",
    "                                        x = df_temp[['sum_sentiment', 'close_lag_1']]\n",
    "                                        x.sum_sentiment = x.sum_sentiment.astype(str)\n",
    "\n",
    "                                        x = pd.get_dummies(x, drop_first=True)\n",
    "                                        y = df_temp.close\n",
    "                                        x2 = sm.add_constant(x)\n",
    "                                        lm = sm.OLS(y, x2)\n",
    "                                        res_lm = lm.fit()\n",
    "\n",
    "                                        res['const'] = res_lm.params[0]\n",
    "                                        res[f'{x.columns[0]}_coef'] = res_lm.params[1]\n",
    "                                        res[f'{x.columns[1]}_coef'] = res_lm.params[2]\n",
    "                                        res[f'{x.columns[2]}_coef'] = res_lm.params[3]\n",
    "\n",
    "                                        res['const_p'] = res_lm.pvalues[0]\n",
    "                                        res[f'{x.columns[0]}_p'] = res_lm.pvalues[1]\n",
    "                                        res[f'{x.columns[1]}_p'] = res_lm.pvalues[2]\n",
    "                                        res[f'{x.columns[2]}_p'] = res_lm.pvalues[3]\n",
    "                                        res['r2'] = res_lm.rsquared\n",
    "                                        res['nobs'] = res_lm.nobs\n",
    "                                        counter += 1\n",
    "                                        print(counter, end='\\r')\n",
    "\n",
    "\n",
    "                                        res = pd.DataFrame.from_dict(res)\n",
    "\n",
    "                                        out = out.append(pd.DataFrame(res))\n",
    "                                        if counter % 100 == 0: \n",
    "                                            out.to_excel(f'/is/res/nb/mag_nb_model_ind_final1.xlsx', index=False)\n",
    "\n",
    "                        except:\n",
    "                            continue\n",
    "    \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "out.to_excel(f'/is/res/nb/mag_nb_model_ind_final1.xlsx', index=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
